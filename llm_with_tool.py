import os
import requests
import asyncio
import json
from typing import List, Dict, Any
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

# ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–é…ç½®
OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')
OPENROUTER_BASE_URL = os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1')
DIFY_BASE_URL = os.getenv('DIFY_BASE_URL', 'http://localhost')
DIFY_DATASET_ID = os.getenv('DIFY_DATASET_ID')
DIFY_API_KEY = os.getenv('DIFY_API_KEY')

@tool
def dify_retrieve(query: str, user_id: str = "1", top_k: int = 5) -> str:
    """
    ä»Ž Dify çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚
    
    è¿™ä¸ªå·¥å…·å¯ä»¥æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ä»Ž Dify çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚
    é€‚ç”¨äºŽéœ€è¦èŽ·å–ç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€æ–‡æ¡£å†…å®¹æˆ–å›žç­”åŸºäºŽçŸ¥è¯†åº“çš„é—®é¢˜ã€‚
    
    Args:
        query (str): è¦æ£€ç´¢çš„æŸ¥è¯¢æ–‡æœ¬ï¼Œä¾‹å¦‚ "ç”Ÿæ€å†œä¸šçš„å‘å±•è¶‹åŠ¿"
        user_id (str, optional): ç”¨æˆ·æ ‡è¯†ç¬¦ï¼Œç”¨äºŽ Dify ç»Ÿè®¡ã€‚é»˜è®¤ä¸º "1"
        top_k (int, optional): è¿”å›žçš„æœ€å¤§ç»“æžœæ•°é‡ã€‚é»˜è®¤ä¸º 5
        
    Returns:
        str: æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æžœï¼ŒåŒ…å«ç›¸å…³æ–‡æ¡£ç‰‡æ®µçš„å†…å®¹
        
    Example:
        >>> result = dify_retrieve("ç”Ÿæ€å†œä¸š")
        >>> print(result)
        æ£€ç´¢åˆ° 3 æ¡ç›¸å…³è®°å½•:
        1. [ä½ç½®: 14] ç”Ÿæ€å†œä¸šæ˜¯ä¸€ç§å¯æŒç»­çš„å†œä¸šå‘å±•æ¨¡å¼...
        2. [ä½ç½®: 25] ç”Ÿæ€å†œä¸šæ³¨é‡çŽ¯å¢ƒä¿æŠ¤å’Œèµ„æºå¾ªçŽ¯åˆ©ç”¨...
        3. [ä½ç½®: 42] çŽ°ä»£ç”Ÿæ€å†œä¸šæŠ€æœ¯åŒ…æ‹¬æœ‰æœºç§æ¤ã€ç”Ÿç‰©é˜²æ²»...
    """
    
    # æž„å»º API ç«¯ç‚¹ URL
    url = f'{DIFY_BASE_URL}/v1/datasets/{DIFY_DATASET_ID}/retrieve'
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'Authorization': f'Bearer {DIFY_API_KEY}',
        'Content-Type': 'application/json',
    }
    
    # æž„å»ºè¯·æ±‚æ•°æ®
    data = {
        "inputs": {},
        "query": query,
        "response_mode": "blocking",
        "conversation_id": "",
        "user": user_id,
        "retrieval_setting": {
            "top_k": top_k
        }
    }
    
    try:
        # å‘é€ POST è¯·æ±‚åˆ° Dify API
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if response.status_code == 200:
            try:
                # è§£æž JSON å“åº”
                json_response = response.json()
                
                # æ ¼å¼åŒ–æ£€ç´¢ç»“æžœ
                return _format_retrieve_results(json_response, query)
                
            except json.JSONDecodeError:
                return f"âŒ è§£æžå“åº”å¤±è´¥ï¼šå“åº”ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼\nåŽŸå§‹å“åº”: {response.text[:500]}"
                
        else:
            return f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}\né”™è¯¯ä¿¡æ¯: {response.text[:500]}"
            
    except requests.exceptions.ConnectionError:
        return "âŒ è¿žæŽ¥é”™è¯¯ï¼šæ— æ³•è¿žæŽ¥åˆ° Dify æœåŠ¡å™¨ã€‚è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œä¸”ç½‘ç»œè¿žæŽ¥æ­£å¸¸ã€‚"
    except requests.exceptions.Timeout:
        return "âŒ è¯·æ±‚è¶…æ—¶ï¼šDify æœåŠ¡å™¨å“åº”æ—¶é—´è¿‡é•¿ï¼Œè¯·ç¨åŽé‡è¯•ã€‚"
    except requests.exceptions.RequestException as e:
        return f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}"


def _format_retrieve_results(response_data: Dict[str, Any], original_query: str) -> str:
    """
    æ ¼å¼åŒ– Dify æ£€ç´¢ç»“æžœä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²æ ¼å¼
    
    Args:
        response_data: Dify API è¿”å›žçš„ JSON æ•°æ®
        original_query: åŽŸå§‹æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        str: æ ¼å¼åŒ–åŽçš„ç»“æžœå­—ç¬¦ä¸²
    """
    
    # èŽ·å–æŸ¥è¯¢å†…å®¹
    query_content = response_data.get('query', {}).get('content', original_query)
    
    # èŽ·å–æ£€ç´¢è®°å½•
    records = response_data.get('records', [])
    
    if not records:
        return f"ðŸ“ æŸ¥è¯¢: {query_content}\nâŒ æœªæ‰¾åˆ°ç›¸å…³è®°å½•ï¼Œè¯·å°è¯•è°ƒæ•´æŸ¥è¯¢å…³é”®è¯ã€‚"
    
    # æž„å»ºç»“æžœå­—ç¬¦ä¸²
    result_lines = [
        f"ðŸ“ æŸ¥è¯¢: {query_content}",
        f"ðŸ“Š æ£€ç´¢åˆ° {len(records)} æ¡ç›¸å…³è®°å½•:\n"
    ]
    
    for i, record in enumerate(records, 1):
        segment = record.get('segment', {})
        position = segment.get('position', 'æœªçŸ¥ä½ç½®')
        content = segment.get('content', 'æ— å†…å®¹')
        
        # æ¸…ç†å†…å®¹ï¼šç§»é™¤å¤šä½™çš„æ¢è¡Œç¬¦å’Œç©ºæ ¼
        cleaned_content = ' '.join(content.split())       
        result_lines.append(f"{i}. [ä½ç½®: {position}] {cleaned_content}")
    
    return "\n".join(result_lines)


async def stream_with_token_output():
    """ä½¿ç”¨ astream_events å®žçŽ°é€ token æµå¼è¾“å‡º"""
    
    # åˆ›å»ºLLMå®žä¾‹ï¼Œå¿…é¡»è®¾ç½® streaming=True
    llm = ChatOpenAI(
        model="google/gemini-2.5-flash",
        api_key=OPENROUTER_API_KEY,
        base_url=OPENROUTER_BASE_URL,
        temperature=0.7,
        streaming=True  # å…³é”®ï¼šå¯ç”¨æµå¼è¾“å‡º
    )
    
    # åˆ›å»ºReAct Agent
    agent = create_react_agent(
        model=llm,
        tools=[dify_retrieve],
        prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥æ£€ç´¢ä¿¡æ¯å¹¶å›žç­”ç”¨æˆ·é—®é¢˜ã€‚è¯·åŸºäºŽæ£€ç´¢åˆ°çš„ä¿¡æ¯ç»™å‡ºè¯¦ç»†ã€æœ‰ç”¨çš„å›žç­”ã€‚"
    )
    
    test_query = "è¯·å¸®æˆ‘æŸ¥è¯¢ç”Ÿæ€å†œä¸šç›¸å…³çš„ä¿¡æ¯"
    print(f"ðŸ¤– å‘Agentå‘é€æŸ¥è¯¢: {test_query}")
    print("=" * 60)
    
    # ä½¿ç”¨ astream_events èŽ·å–æ¯ä¸ªäº‹ä»¶
    async for event in agent.astream_events(
        {"messages": [{"role": "user", "content": test_query}]},
        version="v1"  # ä½¿ç”¨ v1 ç‰ˆæœ¬çš„ API
    ):
        event_type = event.get("event")
        event_name = event.get("name", "")
        
        # æ•èŽ· LLM å¼€å§‹æ€è€ƒ
        if event_type == "on_chat_model_start":
            print(f"\nðŸ§  [{event_name}] å¼€å§‹æ€è€ƒ...")
            
        # æ•èŽ·æ¯ä¸ª token çš„è¾“å‡º
        elif event_type == "on_chat_model_stream":
            chunk = event.get("data", {}).get("chunk", {})
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end="", flush=True)
                
        # æ•èŽ· LLM å®Œæˆæ€è€ƒ
        elif event_type == "on_chat_model_end":
            print(f"\nâœ… [{event_name}] æ€è€ƒå®Œæˆ")
            
        # æ•èŽ·å·¥å…·è°ƒç”¨å¼€å§‹
        elif event_type == "on_tool_start":
            tool_name = event.get("name", "")
            tool_input = event.get("data", {}).get("input", {})
            print(f"\nðŸ”§ [{tool_name}] å¼€å§‹æ‰§è¡Œå·¥å…·")
            print(f"   å‚æ•°: {json.dumps(tool_input, ensure_ascii=False)}")
            
        # æ•èŽ·å·¥å…·æ‰§è¡Œç»“æžœ
        elif event_type == "on_tool_end":
            tool_name = event.get("name", "")
            tool_output = event.get("data", {}).get("output", "")
            print(f"\nâš¡ [{tool_name}] å·¥å…·æ‰§è¡Œå®Œæˆ")
            
            # æ­£ç¡®å¤„ç†ä¸åŒç±»åž‹çš„è¾“å‡º
            if hasattr(tool_output, 'content'):
                output_content = tool_output.content
            elif isinstance(tool_output, str):
                output_content = tool_output
            else:
                output_content = str(tool_output)
                
            # æ˜¾ç¤ºç»“æžœçš„å‰100ä¸ªå­—ç¬¦
            if len(output_content) > 100:
                print(f"   ç»“æžœ: {output_content[:100]}...")
            else:
                print(f"   ç»“æžœ: {output_content}")

if __name__ == "__main__":
    asyncio.run(stream_with_token_output())