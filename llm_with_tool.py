import os
import asyncio
import json
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from dotenv import load_dotenv
from dify_retrieval_enhanced import enhanced_retrieve

load_dotenv()

async def stream_with_token_output():
    llm = ChatOpenAI(
        model="google/gemini-2.5-flash",
        api_key=os.getenv('OPENROUTER_API_KEY'),
        base_url=os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1'),
        temperature=0.7,
        streaming=True
    )
    
    agent = create_react_agent(
        model=llm,
        tools=[enhanced_retrieve],
        prompt="""
        ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥æ£€ç´¢ä¿¡æ¯å¹¶å›žç­”ç”¨æˆ·é—®é¢˜ã€‚
        å‡å¦‚ä½ è¿žæŽ¥æ•°æ®åº“å¤±è´¥ï¼Œå°±ä½¿ç”¨ä½ è‡ªå·±çš„çŸ¥è¯†è¿›è¡Œå›žç­”ã€‚
        """
    )
    
    test_query = "è¯·å¸®æˆ‘æŸ¥è¯¢ç”Ÿæ€å†œä¸šç›¸å…³çš„ä¿¡æ¯"
    print(f"ðŸ¤– æŸ¥è¯¢: {test_query}")
    print("=" * 60)
    
    async for event in agent.astream_events(
        {"messages": [{"role": "user", "content": test_query}]},
        version="v1"
    ):
        event_type = event.get("event")
        
        if event_type == "on_chat_model_stream":
            chunk = event.get("data", {}).get("chunk", {})
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end="", flush=True)
                
        elif event_type == "on_tool_start":
            tool_name = event.get("name", "")
            tool_input = event.get("data", {}).get("input", {})
            print(f"\nðŸ”§ [{tool_name}] æ‰§è¡Œä¸­...")
            print(f"å‚æ•°: {json.dumps(tool_input, ensure_ascii=False)}")
            
        elif event_type == "on_tool_end":
            tool_name = event.get("name", "")
            tool_output = event.get("data", {}).get("output", "")
            print(f"\nâš¡ [{tool_name}] å®Œæˆ")
            
            output_content = tool_output.content if hasattr(tool_output, 'content') else str(tool_output)
            print(f"ç»“æžœ: {output_content[:100]}..." if len(output_content) > 100 else f"ç»“æžœ: {output_content}")

if __name__ == "__main__":
    asyncio.run(stream_with_token_output())