import requests
import json
from typing import List, Dict, Any, Optional

# Dify é…ç½®å¸¸é‡
DIFY_BASE_URL = 'http://localhost'
ABSTRACT_DATASET_ID = '5a36aa21-0aa7-433e-bdab-72aa9931b543'
FULL_TEXT_DATASET_ID = '8e162a14-c930-40a9-8395-39502b58a45b'
DIFY_API_KEY = 'dataset-nn9K2CMUXa9rSKLlNpMwmHU7'

def retrieve_from_abstract_dataset(query: str, top_k: int = 5) -> Dict[str, Any]:
    """ä»abstract datasetä¸­æ£€ç´¢å†…å®¹"""
    url = f'{DIFY_BASE_URL}/v1/datasets/{ABSTRACT_DATASET_ID}/retrieve'
    headers = {
        'Authorization': f'Bearer {DIFY_API_KEY}',
        'Content-Type': 'application/json',
    }
    data = {
        "inputs": {},
        "query": query,
        "response_mode": "blocking",
        "conversation_id": "",
        "user": "1",
        "retrieval_setting": {
            "top_k": top_k
        }
    }
    
    response = requests.post(url, headers=headers, json=data, timeout=30)
    if response.status_code == 200:
        return response.json()
    return {}

def get_document_by_case_id(case_id: str) -> Optional[str]:
    """æ ¹æ®case_idä»full text datasetä¸­è·å–å®Œæ•´æ–‡æ¡£å†…å®¹"""
    # é¦–å…ˆè·å–æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨
    url = f'{DIFY_BASE_URL}/v1/datasets/{FULL_TEXT_DATASET_ID}/documents'
    headers = {
        'Authorization': f'Bearer {DIFY_API_KEY}',
        'Content-Type': 'application/json',
    }
    
    response = requests.get(url, headers=headers, timeout=30)
    if response.status_code != 200:
        return None
    
    documents_data = response.json()
    documents = documents_data.get('data', [])
    
    # æŸ¥æ‰¾åŒ¹é…case_idçš„æ–‡æ¡£
    target_document_id = None
    for doc in documents:
        doc_metadata = doc.get('doc_metadata', [])
        for metadata in doc_metadata:
            if metadata.get('name') == 'case_id' and metadata.get('value') == str(case_id):
                target_document_id = doc.get('id')
                break
        if target_document_id:
            break
    
    if not target_document_id:
        return None
    
    # è·å–æ–‡æ¡£çš„æ‰€æœ‰segments
    segments_url = f'{DIFY_BASE_URL}/v1/datasets/{FULL_TEXT_DATASET_ID}/documents/{target_document_id}/segments'
    segments_response = requests.get(segments_url, headers=headers, timeout=30)
    
    if segments_response.status_code != 200:
        return None
    
    segments_data = segments_response.json()
    segments = segments_data.get('data', [])
    
    # åˆå¹¶æ‰€æœ‰segmentçš„å†…å®¹
    full_content = []
    for segment in sorted(segments, key=lambda x: x.get('position', 0)):
        content = segment.get('content', '')
        if content.strip():
            full_content.append(content.strip())
    
    return '\n\n'.join(full_content)

def enhanced_retrieve(query: str, top_k: int = 3) -> str:
    """
    å¢å¼ºæ£€ç´¢æµç¨‹ï¼š
    1. ä»abstract datasetä¸­æ£€ç´¢
    2. æå–case_id
    3. ä»full text datasetä¸­è·å–å®Œæ•´æ–‡æ¡£
    """
    print(f"ğŸ” å¼€å§‹å¢å¼ºæ£€ç´¢: {query}")
    print("="*60)
    
    # æ­¥éª¤1: ä»abstract datasetæ£€ç´¢
    print("ğŸ“ æ­¥éª¤1: ä»abstract datasetæ£€ç´¢ç›¸å…³å†…å®¹...")
    abstract_results = retrieve_from_abstract_dataset(query, top_k)
    
    records = abstract_results.get('records', [])
    if not records:
        return f"âŒ åœ¨abstract datasetä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
    
    print(f"âœ… åœ¨abstract datasetä¸­æ‰¾åˆ° {len(records)} æ¡ç›¸å…³è®°å½•")
    
    # æ­¥éª¤2: æå–case_idå¹¶è·å–å®Œæ•´æ–‡æ¡£
    full_documents = []
    processed_case_ids = set()
    
    for i, record in enumerate(records, 1):
        # ä¿®æ­£ï¼šcase_idåœ¨document.doc_metadataä¸­ï¼Œä¸æ˜¯åœ¨segment.metadataä¸­
        document = record.get('segment', {}).get('document', {})
        doc_metadata = document.get('doc_metadata', {})
        case_id = doc_metadata.get('case_id')
        
        if not case_id or case_id in processed_case_ids:
            continue
            
        processed_case_ids.add(case_id)
        
        print(f"ğŸ“„ æ­¥éª¤2.{i}: è·å–case_id={case_id}çš„å®Œæ•´æ–‡æ¡£...")
        full_content = get_document_by_case_id(case_id)
        
        if full_content:
            full_documents.append({
                'case_id': case_id,
                'content': full_content,
                'abstract_snippet': record.get('segment', {}).get('content', '')[:200] + '...'
            })
            print(f"âœ… æˆåŠŸè·å–case_id={case_id}çš„å®Œæ•´æ–‡æ¡£ ({len(full_content)}å­—ç¬¦)")
        else:
            print(f"âŒ æœªèƒ½è·å–case_id={case_id}çš„å®Œæ•´æ–‡æ¡£")
    
    # æ­¥éª¤3: æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    if not full_documents:
        return "âŒ æœªèƒ½è·å–åˆ°ä»»ä½•å®Œæ•´æ–‡æ¡£"
    
    result_lines = [
        f"ğŸ“Š æ£€ç´¢ç»“æœæ€»ç»“:",
        f"- æŸ¥è¯¢: {query}",
        f"- Abstractæ£€ç´¢åˆ°: {len(records)} æ¡è®°å½•",
        f"- è·å–å®Œæ•´æ–‡æ¡£: {len(full_documents)} ä¸ª",
        "",
        "ğŸ“š å®Œæ•´æ–‡æ¡£å†…å®¹:"
    ]
    
    for i, doc in enumerate(full_documents, 1):
        result_lines.extend([
            f"\n{'='*50}",
            f"æ–‡æ¡£ {i}: Case ID = {doc['case_id']}",
            f"{'='*50}",
            f"æ‘˜è¦ç‰‡æ®µ: {doc['abstract_snippet']}",
            f"\nå®Œæ•´å†…å®¹:",
            doc['content']
        ])
    
    return '\n'.join(result_lines)

if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºæ£€ç´¢åŠŸèƒ½
    test_query = "æœ´æ„¿æœ‰æœºå†œè€•ç§‘æ™®å›­"
    print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
    print(f"{'='*80}")
    result = enhanced_retrieve(test_query)
    print(result)