import requests
import json
from typing import List, Dict, Any, Optional
from langchain_core.tools import tool

# Dify é…ç½®å¸¸é‡
DIFY_BASE_URL = 'http://localhost'
ABSTRACT_DATASET_ID = '5a36aa21-0aa7-433e-bdab-72aa9931b543'
FULL_TEXT_DATASET_ID = '8e162a14-c930-40a9-8395-39502b58a45b'
DIFY_API_KEY = 'dataset-nn9K2CMUXa9rSKLlNpMwmHU7'

def retrieve_from_abstract_dataset(query: str, top_k: int = 5) -> Dict[str, Any]:
    """ä»abstract datasetä¸­æ£€ç´¢å†…å®¹"""
    url = f'{DIFY_BASE_URL}/v1/datasets/{ABSTRACT_DATASET_ID}/retrieve'
    headers = {
        'Authorization': f'Bearer {DIFY_API_KEY}',
        'Content-Type': 'application/json',
    }
    data = {
        "inputs": {},
        "query": query,
        "response_mode": "blocking",
        "conversation_id": "",
        "user": "1",
        "retrieval_setting": {
            "top_k": top_k
        }
    }
    
    response = requests.post(url, headers=headers, json=data, timeout=30)
    if response.status_code == 200:
        return response.json()
    return {}

def get_document_by_case_id(case_id: str) -> Optional[str]:
    """æ ¹æ®case_idä»full text datasetä¸­è·å–å®Œæ•´æ–‡æ¡£å†…å®¹"""
    url = f'{DIFY_BASE_URL}/v1/datasets/{FULL_TEXT_DATASET_ID}/documents'
    headers = {
        'Authorization': f'Bearer {DIFY_API_KEY}',
        'Content-Type': 'application/json',
    }
    
    response = requests.get(url, headers=headers, timeout=30)
    if response.status_code != 200:
        return None
    
    documents_data = response.json()
    documents = documents_data.get('data', [])
    
    target_document_id = None
    for doc in documents:
        doc_metadata = doc.get('doc_metadata', [])
        for metadata in doc_metadata:
            if metadata.get('name') == 'case_id' and metadata.get('value') == str(case_id):
                target_document_id = doc.get('id')
                break
        if target_document_id:
            break
    
    if not target_document_id:
        return None
    
    segments_url = f'{DIFY_BASE_URL}/v1/datasets/{FULL_TEXT_DATASET_ID}/documents/{target_document_id}/segments'
    segments_response = requests.get(segments_url, headers=headers, timeout=30)
    
    if segments_response.status_code != 200:
        return None
    
    segments_data = segments_response.json()
    segments = segments_data.get('data', [])
    
    full_content = []
    for segment in sorted(segments, key=lambda x: x.get('position', 0)):
        content = segment.get('content', '')
        if content.strip():
            full_content.append(content.strip())
    
    return '\n\n'.join(full_content)

@tool
def enhanced_retrieve(query: str, top_k: int = 3) -> str:
    """
    ä» Dify çŸ¥è¯†åº“ä¸­è¿›è¡Œå¢å¼ºæ£€ç´¢ï¼Œè·å–å®Œæ•´æ–‡æ¡£å†…å®¹ã€‚
    
    è¿™ä¸ªå·¥å…·å®ç°ä¸¤é˜¶æ®µæ£€ç´¢ï¼š
    1. é¦–å…ˆä»æ‘˜è¦æ•°æ®é›†ä¸­æ£€ç´¢ç›¸å…³å†…å®¹
    2. ç„¶åæ ¹æ®case_idä»å®Œæ•´æ–‡æ¡£æ•°æ®é›†ä¸­è·å–å®Œæ•´æ–‡æ¡£å†…å®¹
    
    é€‚ç”¨äºéœ€è¦è·å–å®Œæ•´æ¡ˆä¾‹æ–‡æ¡£ã€è¯¦ç»†ä¿¡æ¯æˆ–æ·±åº¦åˆ†æçš„åœºæ™¯ã€‚
    
    Args:
        query (str): è¦æ£€ç´¢çš„æŸ¥è¯¢æ–‡æœ¬ï¼Œä¾‹å¦‚ "æœ´æ„¿æœ‰æœºå†œè€•ç§‘æ™®å›­"
        top_k (int, optional): è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡ã€‚é»˜è®¤ä¸º 3
        
    Returns:
        str: æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœï¼ŒåŒ…å«å®Œæ•´æ–‡æ¡£å†…å®¹
        
    Example:
        >>> result = enhanced_retrieve("ç”Ÿæ€å†œä¸šæ¡ˆä¾‹")
        >>> print(result)
        ğŸ“Š æ£€ç´¢ç»“æœæ€»ç»“:
        - æŸ¥è¯¢: ç”Ÿæ€å†œä¸šæ¡ˆä¾‹
        - Abstractæ£€ç´¢åˆ°: 2 æ¡è®°å½•
        - è·å–å®Œæ•´æ–‡æ¡£: 2 ä¸ª
        
        ğŸ“š å®Œæ•´æ–‡æ¡£å†…å®¹:
        æ–‡æ¡£ 1: Case ID = 12345
        å®Œæ•´å†…å®¹: [å®Œæ•´çš„æ¡ˆä¾‹æ–‡æ¡£å†…å®¹...]
    """
    
    # æ­¥éª¤1: ä»abstract datasetæ£€ç´¢
    abstract_results = retrieve_from_abstract_dataset(query, top_k)
    
    records = abstract_results.get('records', [])
    if not records:
        return f"âŒ åœ¨abstract datasetä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
    
    # æ­¥éª¤2: æå–case_idå¹¶è·å–å®Œæ•´æ–‡æ¡£
    full_documents = []
    processed_case_ids = set()
    
    for record in records:
        document = record.get('segment', {}).get('document', {})
        doc_metadata = document.get('doc_metadata', {})
        case_id = doc_metadata.get('case_id')
        
        if not case_id or case_id in processed_case_ids:
            continue
            
        processed_case_ids.add(case_id)
        
        full_content = get_document_by_case_id(case_id)
        
        if full_content:
            full_documents.append({
                'case_id': case_id,
                'content': full_content,
                'abstract_snippet': record.get('segment', {}).get('content', '')[:200] + '...'
            })
    
    # æ­¥éª¤3: æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    if not full_documents:
        return "âŒ æœªèƒ½è·å–åˆ°ä»»ä½•å®Œæ•´æ–‡æ¡£"
    
    result_lines = [
        f"ğŸ“Š æ£€ç´¢ç»“æœæ€»ç»“:",
        f"- æŸ¥è¯¢: {query}",
        f"- Abstractæ£€ç´¢åˆ°: {len(records)} æ¡è®°å½•",
        f"- è·å–å®Œæ•´æ–‡æ¡£: {len(full_documents)} ä¸ª",
        "",
        "ğŸ“š å®Œæ•´æ–‡æ¡£å†…å®¹:"
    ]
    
    for i, doc in enumerate(full_documents, 1):
        result_lines.extend([
            f"\n{'='*50}",
            f"æ–‡æ¡£ {i}: Case ID = {doc['case_id']}",
            f"{'='*50}",
            f"æ‘˜è¦ç‰‡æ®µ: {doc['abstract_snippet']}",
            f"\nå®Œæ•´å†…å®¹:",
            doc['content']
        ])
    
    return '\n'.join(result_lines)

if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºæ£€ç´¢åŠŸèƒ½
    test_query = "æœ´æ„¿æœ‰æœºå†œè€•ç§‘æ™®å›­"
    print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
    print(f"{'='*80}")
    result = enhanced_retrieve.invoke({"query": test_query})
    print(result)